# -*- coding: utf-8 -*-
"""inference
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1ZyDQ-o3pfPEg9O8t2oigAeQapaMBpqe2
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
import matplotlib.pyplot as plt
import numpy as np
import copy
import os
import random
import shutil
import time
from PIL import Image
from torch.autograd import Variable

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)


ROOT = "/content/drive/MyDrive"

images_dir = os.path.join(ROOT, 'images')
train_labeled_dir = os.path.join(images_dir, 'training_labeled_images')
test_labeled_dir = os.path.join(images_dir, 'testing_labeled_images')


BATCH_SIZE = 32
train_data = datasets.ImageFolder(root=train_labeled_dir,
                                  transform=transforms.ToTensor())
# calculate mean and std which is used in transforms parameter.
means = torch.zeros(3)
stds = torch.zeros(3)

for img, label in train_data:
    means += torch.mean(img, dim=(1, 2))
    stds += torch.std(img, dim=(1, 2))
# setting image to fit pretrained model.
pretrained_size = 224
means /= len(train_data)
stds /= len(train_data)

print(f'Calculated means: {means}')
print(f'Calculated stds: {stds}')


test_transforms = transforms.Compose([
                           transforms.Resize(pretrained_size),
                           transforms.CenterCrop(pretrained_size),
                           transforms.ToTensor(),
                           transforms.Normalize(mean=means, std=stds),
                       ])

test_data = datasets.ImageFolder(root=test_labeled_dir,
                                 transform=test_transforms)


pretrained_model = models.resnet152(pretrained=True)
IN_FEATURES = pretrained_model.fc.in_features
OUTPUT_DIM = len(test_data.classes)
optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)
pretrained_model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)
pretrained_model = pretrained_model.to(device)


checkpoint = torch.load("/content/drive/MyDrive/Adjust_resnet152.pth")
pretrained_model.load_state_dict(checkpoint["model_state_dict"])
optimizer.load_state_dict(checkpoint["optimizer_state_dict"])

pretrained_model.eval()
path = "/content/drive/MyDrive/images/testing_images"


def image_loader(image_name):
    """load image, returns cuda tensor"""
    image = Image.open(image_name)
    image = loader(image).float()
    image = Variable(image, requires_grad=True)
    image = image.unsqueeze(0)  # this is for VGG, may not be needed for ResNet
    return image  # assumes that you're using GPU

loader = transforms.Compose([
                           transforms.Resize(pretrained_size),
                           transforms.CenterCrop(pretrained_size),
                           transforms.ToTensor(),
                           transforms.Normalize(mean=means, std=stds)
                           ])
dicts = {}
keys = range(200)
with open('/content/drive/MyDrive/classes.txt') as f:
    values = [x.strip() for x in f.readlines()]
    for i in keys:
        dicts[i] = values[i]

print(dict(list(enumerate(values))))


with open('/content/drive/MyDrive/testing_img_order.txt') as f:
    test_images = [x.strip() for x in f.readlines()]  # all the testing images

submission = []
for img in test_images:  # image order is important to your result
    img_path = os.path.join(path, img)
    # print(img_path)
    image = image_loader(img_path).to(device)
    outputs = pretrained_model(image)
    _, predicted = torch.max(outputs.data, 1)
    # print(predicted)
    s = str(predicted)
    s = int(s.split("[")[1].split("]")[0])
    # print(s)
    # print(s.split("[")[1].split("]")[0])
    # predicted_class = s.split("[")[1].split("]")[0]
    submission.append([img, dicts[s]])
    # print([img, dicts[s]])

np.savetxt("/content/drive/MyDrive/answer.txt", submission, fmt='%s')
