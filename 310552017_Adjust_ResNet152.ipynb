{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VM63m8vIKIA",
    "outputId": "3870ef55-3eb8-4288-9ef8-edcb1482021e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "ROOT = \"/content/drive/MyDrive\"\n",
    "\n",
    "images_dir = os.path.join(ROOT, 'images')\n",
    "train_labeled_dir = os.path.join(images_dir, 'training_labeled_images')\n",
    "test_labeled_dir = os.path.join(images_dir, 'testing_labeled_images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate means, stds using  in transforms as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VM63m8vIKIA",
    "outputId": "3870ef55-3eb8-4288-9ef8-edcb1482021e"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_data = datasets.ImageFolder(root=train_labeled_dir,\n",
    "                                  transform=transforms.ToTensor())\n",
    "# calculate mean and std which is used in transforms parameter.\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim=(1, 2))\n",
    "    stds += torch.std(img, dim=(1, 2))\n",
    "# setting image to fit pretrained model.\n",
    "pretrained_size = 224\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation, data normalization, and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VM63m8vIKIA",
    "outputId": "3870ef55-3eb8-4288-9ef8-edcb1482021e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Calculated means: tensor([0.4819, 0.4976, 0.4321])\n",
      "Calculated stds: tensor([0.1878, 0.1864, 0.1992])\n",
      "Number of training examples: 3000\n",
      "Number of testing examples: 3033\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(pretrained_size, padding=10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means, std=stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means, std=stds),\n",
    "                       ])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_labeled_dir,\n",
    "                                  transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(root=test_labeled_dir,\n",
    "                                 transform=test_transforms)\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True)\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=False)\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZTWzpy3nfUz",
    "outputId": "1b7582f8-e6d7-4d98-d58b-6ba4a4a4c329"
   },
   "source": [
    "# Setting the parameter of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZTWzpy3nfUz",
    "outputId": "1b7582f8-e6d7-4d98-d58b-6ba4a4a4c329"
   },
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet152(pretrained=True)\n",
    "# setting the input size and output size to fit the pretrained model\n",
    "# and the 200 classes of bird images.\n",
    "IN_FEATURES = pretrained_model.fc.in_features\n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "# print(OUTPUT_DIM)\n",
    "pretrained_model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                   patience=3, threshold=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZTWzpy3nfUz",
    "outputId": "1b7582f8-e6d7-4d98-d58b-6ba4a4a4c329"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(train_iterator, 0):\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # print((outputs))\n",
    "            # print((labels))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels == predicted).sum().item()\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(train_iterator)\n",
    "        epoch_acc = 100/BATCH_SIZE*running_correct/len(train_iterator)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f \"\n",
    "              % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        # set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_iterator, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        test_acc))\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZTWzpy3nfUz",
    "outputId": "1b7582f8-e6d7-4d98-d58b-6ba4a4a4c329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 184 s, loss: 5.2241, acc: 2.6263 \n",
      "Accuracy of the network on the test images: 9 %\n",
      "Epoch 2, duration: 184 s, loss: 4.6762, acc: 18.3511 \n",
      "Accuracy of the network on the test images: 23 %\n",
      "Epoch 3, duration: 184 s, loss: 4.0103, acc: 34.7739 \n",
      "Accuracy of the network on the test images: 29 %\n",
      "Epoch 4, duration: 184 s, loss: 3.3874, acc: 45.1463 \n",
      "Accuracy of the network on the test images: 37 %\n",
      "Epoch 5, duration: 184 s, loss: 2.8796, acc: 53.9229 \n",
      "Accuracy of the network on the test images: 42 %\n",
      "Epoch 6, duration: 184 s, loss: 2.4061, acc: 62.7660 \n",
      "Accuracy of the network on the test images: 45 %\n",
      "Epoch 7, duration: 183 s, loss: 2.0279, acc: 70.0133 \n",
      "Accuracy of the network on the test images: 48 %\n",
      "Epoch 8, duration: 183 s, loss: 1.7130, acc: 75.9641 \n",
      "Accuracy of the network on the test images: 50 %\n",
      "Epoch 9, duration: 184 s, loss: 1.4475, acc: 79.9202 \n",
      "Accuracy of the network on the test images: 51 %\n",
      "Epoch 10, duration: 184 s, loss: 1.2119, acc: 83.6769 \n",
      "Accuracy of the network on the test images: 52 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "pretrained_model, training_losses, training_accs, test_accs =\n",
    "train_model(pretrained_model, criterion, optimizer, lrscheduler, n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because of the training accuracy is not very high, training for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDAR7C5YAMiN",
    "outputId": "d1cbfbe6-2f65-430e-87cc-52bb2de0e2ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 184 s, loss: 1.0496, acc: 88.2979 \n",
      "Accuracy of the network on the test images: 53 %\n",
      "Epoch 2, duration: 184 s, loss: 1.0065, acc: 90.0598 \n",
      "Accuracy of the network on the test images: 53 %\n",
      "Epoch 3, duration: 184 s, loss: 0.9934, acc: 90.5253 \n",
      "Accuracy of the network on the test images: 53 %\n",
      "Epoch 4, duration: 184 s, loss: 0.9866, acc: 90.1263 \n",
      "Accuracy of the network on the test images: 54 %\n",
      "Epoch 5, duration: 184 s, loss: 0.9597, acc: 90.5253 \n",
      "Accuracy of the network on the test images: 54 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "pretrained_model, training_losses, training_accs, test_accs =\n",
    "train_model(pretrained_model, criterion, optimizer, lrscheduler, n_epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31Zo4DKe0hre"
   },
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5CaiBbL0_4N"
   },
   "outputs": [],
   "source": [
    "torch.save({\"model_state_dict\": pretrained_model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict()},\n",
    "           \"/content/drive/MyDrive/Adjust_resnet152.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwnchDsxDB9N"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/content/drive/MyDrive/Adjust_resnet152.pth\")\n",
    "pretrained_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model to predict the test image and save the labels in answer.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDTsM8tGC_xI",
    "outputId": "40e4139b-8f6c-4d55-e73a-d54207d985f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '001.Black_footed_Albatross', 1: '002.Laysan_Albatross', 2: '003.Sooty_Albatross', 3: '004.Groove_billed_Ani', 4: '005.Crested_Auklet', 5: '006.Least_Auklet', 6: '007.Parakeet_Auklet', 7: '008.Rhinoceros_Auklet', 8: '009.Brewer_Blackbird', 9: '010.Red_winged_Blackbird', 10: '011.Rusty_Blackbird', 11: '012.Yellow_headed_Blackbird', 12: '013.Bobolink', 13: '014.Indigo_Bunting', 14: '015.Lazuli_Bunting', 15: '016.Painted_Bunting', 16: '017.Cardinal', 17: '018.Spotted_Catbird', 18: '019.Gray_Catbird', 19: '020.Yellow_breasted_Chat', 20: '021.Eastern_Towhee', 21: '022.Chuck_will_Widow', 22: '023.Brandt_Cormorant', 23: '024.Red_faced_Cormorant', 24: '025.Pelagic_Cormorant', 25: '026.Bronzed_Cowbird', 26: '027.Shiny_Cowbird', 27: '028.Brown_Creeper', 28: '029.American_Crow', 29: '030.Fish_Crow', 30: '031.Black_billed_Cuckoo', 31: '032.Mangrove_Cuckoo', 32: '033.Yellow_billed_Cuckoo', 33: '034.Gray_crowned_Rosy_Finch', 34: '035.Purple_Finch', 35: '036.Northern_Flicker', 36: '037.Acadian_Flycatcher', 37: '038.Great_Crested_Flycatcher', 38: '039.Least_Flycatcher', 39: '040.Olive_sided_Flycatcher', 40: '041.Scissor_tailed_Flycatcher', 41: '042.Vermilion_Flycatcher', 42: '043.Yellow_bellied_Flycatcher', 43: '044.Frigatebird', 44: '045.Northern_Fulmar', 45: '046.Gadwall', 46: '047.American_Goldfinch', 47: '048.European_Goldfinch', 48: '049.Boat_tailed_Grackle', 49: '050.Eared_Grebe', 50: '051.Horned_Grebe', 51: '052.Pied_billed_Grebe', 52: '053.Western_Grebe', 53: '054.Blue_Grosbeak', 54: '055.Evening_Grosbeak', 55: '056.Pine_Grosbeak', 56: '057.Rose_breasted_Grosbeak', 57: '058.Pigeon_Guillemot', 58: '059.California_Gull', 59: '060.Glaucous_winged_Gull', 60: '061.Heermann_Gull', 61: '062.Herring_Gull', 62: '063.Ivory_Gull', 63: '064.Ring_billed_Gull', 64: '065.Slaty_backed_Gull', 65: '066.Western_Gull', 66: '067.Anna_Hummingbird', 67: '068.Ruby_throated_Hummingbird', 68: '069.Rufous_Hummingbird', 69: '070.Green_Violetear', 70: '071.Long_tailed_Jaeger', 71: '072.Pomarine_Jaeger', 72: '073.Blue_Jay', 73: '074.Florida_Jay', 74: '075.Green_Jay', 75: '076.Dark_eyed_Junco', 76: '077.Tropical_Kingbird', 77: '078.Gray_Kingbird', 78: '079.Belted_Kingfisher', 79: '080.Green_Kingfisher', 80: '081.Pied_Kingfisher', 81: '082.Ringed_Kingfisher', 82: '083.White_breasted_Kingfisher', 83: '084.Red_legged_Kittiwake', 84: '085.Horned_Lark', 85: '086.Pacific_Loon', 86: '087.Mallard', 87: '088.Western_Meadowlark', 88: '089.Hooded_Merganser', 89: '090.Red_breasted_Merganser', 90: '091.Mockingbird', 91: '092.Nighthawk', 92: '093.Clark_Nutcracker', 93: '094.White_breasted_Nuthatch', 94: '095.Baltimore_Oriole', 95: '096.Hooded_Oriole', 96: '097.Orchard_Oriole', 97: '098.Scott_Oriole', 98: '099.Ovenbird', 99: '100.Brown_Pelican', 100: '101.White_Pelican', 101: '102.Western_Wood_Pewee', 102: '103.Sayornis', 103: '104.American_Pipit', 104: '105.Whip_poor_Will', 105: '106.Horned_Puffin', 106: '107.Common_Raven', 107: '108.White_necked_Raven', 108: '109.American_Redstart', 109: '110.Geococcyx', 110: '111.Loggerhead_Shrike', 111: '112.Great_Grey_Shrike', 112: '113.Baird_Sparrow', 113: '114.Black_throated_Sparrow', 114: '115.Brewer_Sparrow', 115: '116.Chipping_Sparrow', 116: '117.Clay_colored_Sparrow', 117: '118.House_Sparrow', 118: '119.Field_Sparrow', 119: '120.Fox_Sparrow', 120: '121.Grasshopper_Sparrow', 121: '122.Harris_Sparrow', 122: '123.Henslow_Sparrow', 123: '124.Le_Conte_Sparrow', 124: '125.Lincoln_Sparrow', 125: '126.Nelson_Sharp_tailed_Sparrow', 126: '127.Savannah_Sparrow', 127: '128.Seaside_Sparrow', 128: '129.Song_Sparrow', 129: '130.Tree_Sparrow', 130: '131.Vesper_Sparrow', 131: '132.White_crowned_Sparrow', 132: '133.White_throated_Sparrow', 133: '134.Cape_Glossy_Starling', 134: '135.Bank_Swallow', 135: '136.Barn_Swallow', 136: '137.Cliff_Swallow', 137: '138.Tree_Swallow', 138: '139.Scarlet_Tanager', 139: '140.Summer_Tanager', 140: '141.Artic_Tern', 141: '142.Black_Tern', 142: '143.Caspian_Tern', 143: '144.Common_Tern', 144: '145.Elegant_Tern', 145: '146.Forsters_Tern', 146: '147.Least_Tern', 147: '148.Green_tailed_Towhee', 148: '149.Brown_Thrasher', 149: '150.Sage_Thrasher', 150: '151.Black_capped_Vireo', 151: '152.Blue_headed_Vireo', 152: '153.Philadelphia_Vireo', 153: '154.Red_eyed_Vireo', 154: '155.Warbling_Vireo', 155: '156.White_eyed_Vireo', 156: '157.Yellow_throated_Vireo', 157: '158.Bay_breasted_Warbler', 158: '159.Black_and_white_Warbler', 159: '160.Black_throated_Blue_Warbler', 160: '161.Blue_winged_Warbler', 161: '162.Canada_Warbler', 162: '163.Cape_May_Warbler', 163: '164.Cerulean_Warbler', 164: '165.Chestnut_sided_Warbler', 165: '166.Golden_winged_Warbler', 166: '167.Hooded_Warbler', 167: '168.Kentucky_Warbler', 168: '169.Magnolia_Warbler', 169: '170.Mourning_Warbler', 170: '171.Myrtle_Warbler', 171: '172.Nashville_Warbler', 172: '173.Orange_crowned_Warbler', 173: '174.Palm_Warbler', 174: '175.Pine_Warbler', 175: '176.Prairie_Warbler', 176: '177.Prothonotary_Warbler', 177: '178.Swainson_Warbler', 178: '179.Tennessee_Warbler', 179: '180.Wilson_Warbler', 180: '181.Worm_eating_Warbler', 181: '182.Yellow_Warbler', 182: '183.Northern_Waterthrush', 183: '184.Louisiana_Waterthrush', 184: '185.Bohemian_Waxwing', 185: '186.Cedar_Waxwing', 186: '187.American_Three_toed_Woodpecker', 187: '188.Pileated_Woodpecker', 188: '189.Red_bellied_Woodpecker', 189: '190.Red_cockaded_Woodpecker', 190: '191.Red_headed_Woodpecker', 191: '192.Downy_Woodpecker', 192: '193.Bewick_Wren', 193: '194.Cactus_Wren', 194: '195.Carolina_Wren', 195: '196.House_Wren', 196: '197.Marsh_Wren', 197: '198.Rock_Wren', 198: '199.Winter_Wren', 199: '200.Common_Yellowthroat'}\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.eval()\n",
    "path = \"/content/drive/MyDrive/images/testing_images\"\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  # this is for VGG, may not be needed for ResNet\n",
    "    return image  # assumes that you're using GPU\n",
    "\n",
    "loader = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means, std=stds)\n",
    "                           ])\n",
    "dicts = {}\n",
    "keys = range(200)\n",
    "with open('/content/drive/MyDrive/classes.txt') as f:\n",
    "    values = [x.strip() for x in f.readlines()]\n",
    "    for i in keys:\n",
    "        dicts[i] = values[i]\n",
    "\n",
    "print(dict(list(enumerate(values))))\n",
    "\n",
    "\n",
    "with open('/content/drive/MyDrive/testing_img_order.txt') as f:\n",
    "    test_images = [x.strip() for x in f.readlines()]  # all the testing images\n",
    "\n",
    "submission = []\n",
    "for img in test_images:  # image order is important to your result\n",
    "    img_path = os.path.join(path, img)\n",
    "    # print(img_path)\n",
    "    image = image_loader(img_path).to(device)\n",
    "    outputs = pretrained_model(image)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # print(predicted)\n",
    "    s = str(predicted)\n",
    "    s = int(s.split(\"[\")[1].split(\"]\")[0])\n",
    "    # print(s)\n",
    "    # print(s.split(\"[\")[1].split(\"]\")[0])\n",
    "    # predicted_class = s.split(\"[\")[1].split(\"]\")[0]\n",
    "    submission.append([img, dicts[s]])\n",
    "    # print([img, dicts[s]])\n",
    "\n",
    "np.savetxt(\"/content/drive/MyDrive/answer.txt\", submission, fmt='%s')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "310552017_Adjust_ResNet152",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
